{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NREL NSRDB Example\n",
    "\n",
    "This notebook illustrates accessing the NREL NSRDB (National Solar Radiation Database) using both h5pyd with HSDS and h5py with the HDF5 library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "USE_H5PY = False  # set to True to use h5py/hdf5lib instead\n",
    "if USE_H5PY:\n",
    "    import h5py\n",
    "    import s3fs\n",
    "else:\n",
    "    import h5pyd as h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the shell, use the --bucket option to list files from NREL's S3 bucket \n",
    "# run with \"-r\" option to see all domains\n",
    "! hsls --bucket s3://nrel-pds-hsds /nrel/nsrdb/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Open the nsrdb file.  Use the bucket param to get the data from NREL's S3 bucket\n",
    "if USE_H5PY:\n",
    "    s3 = s3fs.S3FileSystem()\n",
    "    f = h5py.File(s3.open(\"s3://nrel-pds-nsrdb/conus/nsrdb_conus_pv_2022.h5\", \"rb\"), \"r\")\n",
    "else:\n",
    "    f = h5py.File(\"/nrel/nsrdb/conus/nsrdb_conus_2022.h5\", bucket=\"s3://nrel-pds-hsds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attributes can be used to provide desriptions of the content\n",
    "%time f.attrs['version']   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(f)  # datasets under root group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = f[\"air_temperature\"]\n",
    "dset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset.id.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset.shape  # two-dimensional  time x station_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset.chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.prod(dset.chunks) * dset.dtype.itemsize   # number of bytes per chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(dset.shape[0] // dset.chunks[0]) * (dset.shape[1] // dset.chunks[0])  # number of chunks in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read one year of measurments for a given station_index\n",
    "%time tseries = dset[::,1234567]\n",
    "tseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get min, max, and mean values\n",
    "tseries.min(), tseries.max(), tseries.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the data\n",
    "x = range(len(tseries))\n",
    "plt.plot(x, tseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This dataset is actually linked from an HDF5 file in a different bucket\n",
    "if USE_H5PY:\n",
    "    # this property doesn't exist for h5py\n",
    "    layout = None\n",
    "else:\n",
    "    layout = dset.id.layout\n",
    "layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The HSDS domain actually maps to several different HDF5 files\n",
    "# compile a list of all the files\n",
    "hdf5_files = set()\n",
    "if not USE_H5PY:\n",
    "    for k in f:\n",
    "        dset = f[k]\n",
    "        layout = dset.id.layout\n",
    "        if \"file_uri\" in layout:\n",
    "            hdf5_files.add(layout[\"file_uri\"])\n",
    "hdf5_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
