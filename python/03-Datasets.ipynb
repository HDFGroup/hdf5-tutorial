{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objectives\n",
    " * Use the h5pyd package to connect with the HDF Lab\n",
    " * Explore characterstics of Datasets (with HDF5Lib and HSDS)\n",
    " * Look at different ways of reading/writing to datasets\n",
    " * Examine how chunking works with HSDS\n",
    " * Tricks for best performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_H5PY = True  # set to False to use HSDS instead\n",
    "if USE_H5PY:\n",
    "    import h5py\n",
    "    WORK_DIR=\".\"  # this directory\n",
    "else:\n",
    "    import h5pyd as h5py\n",
    "    WORK_DIR=\"hdf5://home/test_user1/\"\n",
    "import os.path as op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating HDF5 file here: hdf5://home/test_user1/03.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = op.join(WORK_DIR, \"03.h5\")\n",
    "print(f\"creating HDF5 file here: {filepath}\")\n",
    "f = h5py.File(filepath, 'w')\n",
    "list(f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The 'w' mode removes and existing file (if any) and creates a new empty file.\n",
    "Other modes supported are:\n",
    " * 'r': Open as read only, file must exist\n",
    " * 'r+': Read/write, file must exist\n",
    " * 'x': Create file, fail if exist\n",
    " * 'a': Read/write if exists, otherwise create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'g-74126ce6-cc7ff6fc-fc9a-e46e44-f77e74'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The only object currently in the new file is the root group, we can get the id like this\n",
    "root = f['/']\n",
    "root.id.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"test1\": shape (3, 4), type \"<i8\">"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a new dataset.  Pass in name, shape, and type\n",
    "f.create_dataset(\"test1\", (3,4), dtype='i8')  # we've created a dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test1']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now something shows up if we list the contents of the file\n",
    "list(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The dataset type is fixed at creation time\n",
    "dset = f['test1']\n",
    "dset.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in this case the shape is fixed at create time, though we'll see later it is possible to\n",
    "# create extensible datasets\n",
    "dset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can read all the elements of a dataset using the ellipsis operator\n",
    "out = dset[...]\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 4],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can update portions of the dataset using numpy-like syntax\n",
    "dset[0,0:4] = [1,2,3,4]\n",
    "dset[...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only portions of the dataset that actually get written are stored\n",
    "# create a really big dataset\n",
    "f.create_dataset(\"big_data\", (1024,1024,1024), dtype='f4')  # 4 GB dataset!\n",
    "dset = f['big_data']\n",
    "dset[512,512,512] = 3.12  # write one element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.  , 0.  , 3.12, 0.  ], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read back a small region\n",
    "dset[510:514,512,512]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem: Use h5stat (or hsstat for HSDS) with this file.  How many bytes have been allocatted?\n",
    "Note: hsstat may need a minute before it shows the most recent changes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 128, 128)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset storage is broken up into \"chunks\".  Each chunk is stored as a seperate S3 object\n",
    "# unlike with h5py, datasets are always chunked (even if it is just one chunk!).\n",
    "# Chunks are determined automtically if not provided in the dataset create call\n",
    "dset.chunks  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1024, 1024)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specify a chunk layout\n",
    "f.create_dataset(\"chunked_data\", (1024,1024,1024), dtype='f4',chunks=(1,1024,1024))\n",
    "dset = f[\"chunked_data\"]\n",
    "dset.chunks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem: The server will \"correct\" chunk layouts that result in chunks that are too small or too large.  Try creating datasets with very small and very large chunks.  What chunk layout do you get?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['big_data', 'chunked_data']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete a dataset by using the del operator.  With the HDF5 library, this doesn't leave\n",
    "# \"holes\" in the file (you can use the h5repack tool to defragment.\n",
    "# With HDF Server this is not an issue (since each chunk is stored\n",
    "# as an object).\n",
    "del f['test1']\n",
    "list(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you would like a default value other than 0, specify a \n",
    "#   fill value when creating the dataset\n",
    "f.create_dataset(\"fill_value\", (1024,1024,1024), dtype='i4', fillvalue=42)\n",
    "dset = f['fill_value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([42, 42, 42], dtype=int32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset[1,2,3:6]  # get 3 elements from the array"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem: Run h5stat/hsstat with this file.  How many chunks in the dataset have been allocatted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# release the file handle\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
