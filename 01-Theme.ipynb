{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Theme\n",
    "\n",
    "**Table of contents:**\n",
    " - [Problem formulation](#Problem-formulation)\n",
    " - [Passing arguments to our programs](#Passing-arguments-to-our-programs)\n",
    " - [Creating sample paths](#Creating-sample-paths)\n",
    " - [Writing text files](#Writing-text-files)\n",
    " - [Writing binary files](#Writing-binary-files)\n",
    " - [Writing HDF5 files](#Writing-HDF5-files)\n",
    " - [Visualization](#Visualization)\n",
    " - [Discussion](#Discussion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem formulation\n",
    "\n",
    "Think of a device that over a certain epoch produces time series of measurements. The device could be a physical sensor or a numerical device such as a simulation, or it could be the price of a financial instrument such as a stock. Let's assume we want to capture such time series over many epochs and that each epoch has a fixed number of time steps. A visualization of five such series is shown in the figure (**Source:** __[Wikimedia](https://commons.wikimedia.org/wiki/File:Ornstein-Uhlenbeck-5traces.svg)__) below.\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/6/60/Ornstein-Uhlenbeck-5traces.svg\" title=\"Five sampled traces of an Ornstein-Uhlenbeck process.\" />\n",
    "\n",
    "Assuming that an epoch of length 10 was sampled over 1,000 equidistant time steps, we could conveniently store the underlying data (values of `X`) in a `5 x 1000` two-dimensional array of floating-point values, with the series number and the time step as the row and column index, respectively.\n",
    "\n",
    "For our own benefit and the researchers' with whom we might want to share our observations, we should also record relevant information about the context in which the data was collected. This might be for example the unit of the quantity `X`, the length of an individual time step, the date, time, and location when the recording was made (if that were relvant), and any additional information about the calibration of the generating mechanism. To be specific, in this tutorial, we will use numerical samples of a well-known stochastic process, the so-called __[Ornsteinâ€“Uhlenbeck process](https://en.wikipedia.org/wiki/Ornstein%E2%80%93Uhlenbeck_process)__, as our data source. The sample traces or path samples shown in the figure were actually generated from a numerical experiment of such a process.\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Up to you:</b> To follow this tutorial, it is <i>not</i> necessary to understand what a stochastic process is or how to simulate one. It is OK to think about it as a sophisticated pseudo-random number generator, which merely serves as our source of series data.\n",
    "</div>\n",
    "\n",
    "Our problem formulation is thus: Store the floating-point values of `path_count` series with `step_count` values each in a two-dimensional array of `path_count` rows and `step_count` columns. In addition, store the following floating-point calibrations, which are the same for all series\n",
    "- the time step `dt`\n",
    "- the long-term process mean `mu`\n",
    "- the reversion rate to the mean `theta`\n",
    "- the volatility of the process `sigma`.\n",
    "\n",
    "Before thinking about how to store this data, we will quickly go over how to pass the parameters to our simulation. After all, we want to control how much or how little data to generate! For completeness, we take a quick look at how the series data is generated. (It won't come as a shock that pseudo-random numbers play a big part!) With that out of the way, we look at storing the data in plain text files, as unformatted byte streams, and in HDF5 files. We conclude with a discussion of the advantages and challenges of the three approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passing arguments to our programs\n",
    "\n",
    "We need two helper functions to pass and parse the relevant arguments to our programs.\n",
    "\n",
    "We use Pranav Srinivas Kumar's [`argparse` module](https://github.com/p-ranav/argparse), which is the \"gold standard\" in the C++ world."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile src/parse_arguments.hpp\n",
    "#ifndef PARSE_ARGUMENTS_HPP\n",
    "#define PARSE_ARGUMENTS_HPP\n",
    "\n",
    "#include \"argparse.hpp\"\n",
    "\n",
    "// Sets the options for which we are looking\n",
    "extern void set_options(argparse::ArgumentParser& program);\n",
    "\n",
    "// Tests the options and retrieves the arguments\n",
    "extern int get_arguments\n",
    "(\n",
    "    const argparse::ArgumentParser& program,\n",
    "    size_t&                         path_count,\n",
    "    size_t&                         step_count,\n",
    "    double&                         dt,\n",
    "    double&                         theta,\n",
    "    double&                         mu,\n",
    "    double&                         sigma\n",
    ");\n",
    "\n",
    "#endif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The implementation of our functions is rather unsurprising and speaks to the quality (usability) of `argparse`.\n",
    "\n",
    "In `set_options()`, we inform `argparse` about the program options we want to support. For each argument, we tell `argparse` the short and long forms of the command line argument, a synopsis from which a help message will be created, and the default type and value of the argument. This information guides how `argparse` processes the `main` function's arguments, `argc` and `argv`.\n",
    "\n",
    "In `get_arguments()`, we check if an option was specificed and what value was provided, or use the default value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile src/parse_arguments.cpp\n",
    "\n",
    "#include \"parse_arguments.hpp\"\n",
    "#include <cfloat>\n",
    "#include <iostream>\n",
    "\n",
    "using namespace std;\n",
    "\n",
    "void set_options(argparse::ArgumentParser& program)\n",
    "{\n",
    "    program.add_argument(\"-p\", \"--paths\")  // command line arguments\n",
    "    .help(\"chooses the numnber of paths\")  // synopsis\n",
    "    .default_value(size_t{100})            // default value\n",
    "    .scan<'u', size_t>();                  // expected type\n",
    "\n",
    "    program.add_argument(\"-s\", \"--steps\")\n",
    "    .help(\"chooses the number of steps\")\n",
    "    .default_value(size_t{1000})\n",
    "    .scan<'u', size_t>();\n",
    "\n",
    "    program.add_argument(\"-d\", \"--dt\")\n",
    "    .help(\"chooses the time step\")\n",
    "    .default_value(double{0.01})\n",
    "    .scan<'f', double>();\n",
    "\n",
    "    program.add_argument(\"-t\", \"--theta\")\n",
    "    .help(\"chooses the rate of reversion to the mean\")\n",
    "    .default_value(double{1.0})\n",
    "    .scan<'f', double>();\n",
    "\n",
    "    program.add_argument(\"-m\", \"--mu\")\n",
    "    .help(\"chooses the long-term mean of the process\")\n",
    "    .default_value(double{0.0})\n",
    "    .scan<'f', double>();\n",
    "\n",
    "    program.add_argument(\"-g\", \"--sigma\")\n",
    "    .help(\"chooses the volatility of the process\")\n",
    "    .default_value(double{0.1})\n",
    "    .scan<'f', double>();\n",
    "}\n",
    "\n",
    "int get_arguments\n",
    "(\n",
    "    const argparse::ArgumentParser& program,\n",
    "    size_t&                         path_count,\n",
    "    size_t&                         step_count,\n",
    "    double&                         dt,\n",
    "    double&                         theta,\n",
    "    double&                         mu,\n",
    "    double&                         sigma\n",
    ")\n",
    "{\n",
    "    path_count = program.get<size_t>(\"--paths\");\n",
    "    if (path_count == 0) {\n",
    "        cerr << \"Number of paths must be greater than zero\" << endl;\n",
    "        return -1;\n",
    "    }\n",
    "    step_count = program.get<size_t>(\"--steps\");\n",
    "    if (step_count == 0) {\n",
    "        cerr << \"Number of steps must be greater than zero\" << endl;\n",
    "        return -1;\n",
    "    }\n",
    "    dt = program.get<double>(\"--dt\");\n",
    "    if (dt < DBL_MIN) {\n",
    "        cerr << \"Time step must be greater than zero\" << endl;\n",
    "        return -1;\n",
    "    }\n",
    "    theta = program.get<double>(\"--theta\");\n",
    "    if (theta < DBL_MIN) {\n",
    "        cerr << \"Reversion rate must be greater than zero\" << endl;\n",
    "        return -1;\n",
    "    }\n",
    "    mu = program.get<double>(\"--mu\");\n",
    "    sigma = program.get<double>(\"--sigma\");\n",
    "    if (sigma < DBL_MIN) {\n",
    "        cerr << \"Volatility must be greater than zero\" << endl;\n",
    "        return -1;\n",
    "    }\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make sure the compiler is happy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "g++ -std=c++17 -Wall -pedantic -I./include -c ./src/parse_arguments.cpp -o ./build/parse_arguments.o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating sample paths\n",
    "\n",
    "We create `path_count` sample paths with `step_count` timesteps with the given parameters, and store them in a C++ `vector`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile src/ou_sampler.hpp\n",
    "#ifndef OU_SAMPLER_HPP\n",
    "#define OU_SAMPLER_HPP\n",
    "\n",
    "#include <vector>\n",
    "\n",
    "// Creates `path_count` sample paths of length `step_count` with parameters\n",
    "// `dt`, `theta`, `mu`, and `sigma`\n",
    "extern void ou_sampler\n",
    "(\n",
    "    std::vector<double>& ou_process,\n",
    "    const size_t&        path_count,\n",
    "    const size_t&        step_count,\n",
    "    const double&        dt,\n",
    "    const double&        theta,\n",
    "    const double&        mu,\n",
    "    const double&        sigma\n",
    ");\n",
    "\n",
    "#endif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile src/ou_sampler.cpp\n",
    "\n",
    "#include <random>\n",
    "\n",
    "using namespace std;\n",
    "\n",
    "void ou_sampler\n",
    "(\n",
    "    vector<double>& ou_process,\n",
    "    const size_t&   path_count,\n",
    "    const size_t&   step_count,\n",
    "    const double&   dt,\n",
    "    const double&   theta,\n",
    "    const double&   mu,\n",
    "    const double&   sigma\n",
    ")\n",
    "{\n",
    "    // Store sample paths in one contiguous buffer\n",
    "    ou_process.clear();\n",
    "    ou_process.resize(path_count * step_count);\n",
    "\n",
    "    random_device rd;\n",
    "    mt19937 generator(rd());\n",
    "    normal_distribution<double> dist(0.0, sqrt(dt));\n",
    "\n",
    "    for (size_t i = 0; i < path_count; ++i)\n",
    "    {\n",
    "        ou_process[i * step_count] = 0; // sample paths start at x = 0\n",
    "        for (size_t j = 1; j < step_count; ++j)\n",
    "        {\n",
    "            auto dW = dist(generator);\n",
    "            auto pos = i * step_count + j;\n",
    "            ou_process[pos] = ou_process[pos - 1] + theta * (mu - ou_process[pos - 1]) * dt + sigma * dW;\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "g++ -std=c++17 -Wall -pedantic -c ./src/ou_sampler.cpp -o ./build/ou_sampler.o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing text files\n",
    "\n",
    "The easiest way to store the sample paths would be a text file. We include a header in which we document the parameters that were uses in the generation. This is adequate as long as the number of sample paths and timesteps is relatively small. For large numbers, this is cleary cumbersome and unmanagable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile src/ou_text.cpp\n",
    "#include \"parse_arguments.hpp\"\n",
    "#include \"ou_sampler.hpp\"\n",
    "\n",
    "#include <fstream>\n",
    "#include <vector>\n",
    "\n",
    "using namespace std;\n",
    "\n",
    "int main(int argc, char *argv[])\n",
    "{\n",
    "    size_t path_count, step_count;\n",
    "    double dt, theta, mu, sigma;\n",
    "\n",
    "    argparse::ArgumentParser program(\"ou_text\");\n",
    "    set_options(program);\n",
    "    program.parse_args(argc, argv);\n",
    "    get_arguments(program, path_count, step_count, dt, theta, mu, sigma);\n",
    "\n",
    "    cout << \"Running with parameters:\"\n",
    "         << \" paths=\" << path_count << \" steps=\" << step_count\n",
    "         << \" dt=\" << dt << \" theta=\" << theta << \" mu=\" << mu << \" sigma=\" << sigma << endl;\n",
    "\n",
    "    vector<double> ou_process;\n",
    "    ou_sampler(ou_process, path_count, step_count, dt, theta, mu, sigma);\n",
    "    \n",
    "    // Write the sample paths to a text file\n",
    "    ofstream file(\"ou_process.txt\");\n",
    "    \n",
    "    file << \"# paths steps dt theta mu sigma\" << endl;\n",
    "    file << path_count << \" \" << step_count << \" \" << dt << \" \" << theta << \" \" << mu << \" \" << sigma << endl;\n",
    "    file << \"# data\" << endl;\n",
    "    \n",
    "    for (size_t i = 0; i < path_count; ++i)\n",
    "        {\n",
    "            for (size_t j = 0; j < step_count; ++j)\n",
    "            {\n",
    "                auto pos = i * step_count + j;\n",
    "                file << ou_process[pos] << \" \";\n",
    "            }\n",
    "            file << endl;\n",
    "        }\n",
    "\n",
    "    file.close();\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "g++ -std=c++17 -Wall -pedantic -I./include ./src/ou_text.cpp ./build/parse_arguments.o ./build/ou_sampler.o -o ./build/ou_text\n",
    "./build/ou_text\n",
    "ls -iks ou_process.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing binary files\n",
    "\n",
    "To reduce the file size, instead of using text, we can store the sample paths as an unformatted binary stream. We would need to maintain separate documentation to tell consumers of the data how to parse and interpret this byte stream, which is a minor inconvenience. A major headache is that unformatted binary streams are platform (processor) dependent, which opens the door for misinterpretation when the data is copied to an incompatible platform and not adjusted for this change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile src/ou_binary.cpp\n",
    "#include \"parse_arguments.hpp\"\n",
    "#include \"ou_sampler.hpp\"\n",
    "\n",
    "#include <fstream>\n",
    "#include <vector>\n",
    "\n",
    "using namespace std;\n",
    "\n",
    "int main(int argc, char *argv[])\n",
    "{\n",
    "    size_t path_count, step_count;\n",
    "    double dt, theta, mu, sigma;\n",
    "    \n",
    "    argparse::ArgumentParser program(\"ou_binary\");\n",
    "    set_options(program);\n",
    "    program.parse_args(argc, argv);\n",
    "    get_arguments(program, path_count, step_count, dt, theta, mu, sigma);\n",
    "\n",
    "    cout << \"Running with parameters:\"\n",
    "         << \" paths=\" << path_count << \" steps=\" << step_count\n",
    "         << \" dt=\" << dt << \" theta=\" << theta << \" mu=\" << mu << \" sigma=\" << sigma << endl;\n",
    "\n",
    "    vector<double> ou_process;\n",
    "    ou_sampler(ou_process, path_count, step_count, dt, theta, mu, sigma);\n",
    "    \n",
    "    // Write the sample paths to an unformatted binary file\n",
    "\n",
    "    ofstream file(\"ou_process.bin\", ios::out | ios::binary);\n",
    "    file.write((char *)&path_count, sizeof(path_count));\n",
    "    file.write((char *)&step_count, sizeof(step_count));\n",
    "    file.write((char *)&dt, sizeof(dt));\n",
    "    file.write((char *)&theta, sizeof(theta));\n",
    "    file.write((char *)&mu, sizeof(mu));\n",
    "    file.write((char *)&sigma, sizeof(sigma));\n",
    "    file.write((char *)ou_process.data(), sizeof(double) * ou_process.size());\n",
    "    file.close();\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "g++ -std=c++17 -Wall -pedantic -I./include ./src/ou_binary.cpp ./build/parse_arguments.o ./build/ou_sampler.o -o ./build/ou_binary\n",
    "./build/ou_binary\n",
    "ls -iks ou_process.bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing HDF5 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile src/ou_hdf5.cpp\n",
    "#include \"parse_arguments.hpp\"\n",
    "#include \"ou_sampler.hpp\"\n",
    "\n",
    "#include \"hdf5.h\"\n",
    "#include <vector>\n",
    "\n",
    "using namespace std;\n",
    "\n",
    "int main(int argc, char *argv[])\n",
    "{\n",
    "    size_t path_count, step_count;\n",
    "    double dt, theta, mu, sigma;\n",
    "\n",
    "    argparse::ArgumentParser program(\"ou_hdf5\");\n",
    "    set_options(program);\n",
    "    program.parse_args(argc, argv);\n",
    "    get_arguments(program, path_count, step_count, dt, theta, mu, sigma);\n",
    "\n",
    "    cout << \"Running with parameters:\"\n",
    "         << \" paths=\" << path_count << \" steps=\" << step_count\n",
    "         << \" dt=\" << dt << \" theta=\" << theta << \" mu=\" << mu << \" sigma=\" << sigma << endl;\n",
    "\n",
    "    vector<double> ou_process;\n",
    "    ou_sampler(ou_process, path_count, step_count, dt, theta, mu, sigma);\n",
    "    \n",
    "    //\n",
    "    // Write the sample paths to an HDF5 file using the HDF5 C-API!\n",
    "    //\n",
    "\n",
    "    auto file = H5Fcreate(\"ou_process.h5\", H5F_ACC_TRUNC, H5P_DEFAULT, H5P_DEFAULT);\n",
    "\n",
    "    { // create & write the dataset\n",
    "        hsize_t dimsf[] = {(hsize_t)path_count, (hsize_t)step_count};\n",
    "        auto space = H5Screate_simple(2, dimsf, NULL);\n",
    "        auto dataset = H5Dcreate(file, \"/dataset\", H5T_NATIVE_DOUBLE, space, H5P_DEFAULT, H5P_DEFAULT, H5P_DEFAULT);\n",
    "        H5Dwrite(dataset, H5T_NATIVE_DOUBLE, H5S_ALL, H5S_ALL, H5P_DEFAULT, ou_process.data());\n",
    "        H5Dclose(dataset);\n",
    "        H5Sclose(space);\n",
    "    }\n",
    "\n",
    "    { // make the file self-describing by adding a few attributes to `dataset`\n",
    "        auto scalar = H5Screate(H5S_SCALAR);\n",
    "        auto acpl = H5Pcreate(H5P_ATTRIBUTE_CREATE);\n",
    "        H5Pset_char_encoding(acpl, H5T_CSET_UTF8);\n",
    "        \n",
    "        auto set_attribute = [&](const string& name, const double& value) {\n",
    "            auto attr = H5Acreate_by_name(file, \"dataset\", name.c_str(), H5T_NATIVE_DOUBLE, scalar, acpl, H5P_DEFAULT, H5P_DEFAULT);\n",
    "            H5Awrite(attr, H5T_NATIVE_DOUBLE, &value);\n",
    "            H5Aclose(attr);\n",
    "        };\n",
    "        set_attribute(\"dt\", dt);\n",
    "        set_attribute(\"Î¸\", theta);\n",
    "        set_attribute(\"Î¼\", mu);\n",
    "        set_attribute(\"Ïƒ\", sigma);\n",
    "\n",
    "        H5Pclose(acpl);\n",
    "        H5Sclose(scalar);\n",
    "    }\n",
    "\n",
    "    H5Fclose(file);\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "g++ -std=c++17 -Wall -pedantic -I/usr/include/hdf5/serial -L/usr/lib/x86_64-linux-gnu -I./include  ./src/ou_hdf5.cpp ./build/parse_arguments.o ./build/ou_sampler.o -o ./build/ou_hdf5 -lhdf5_serial\n",
    "./build/ou_hdf5\n",
    "ls -iks ou_process.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "\n",
    "The easiest way to visualize the content of the HDF5 file `ou_process.h5` is to select it in the Explorer. This will launch the __[H5Web VS Code plugin](https://marketplace.visualstudio.com/items?itemName=h5web.vscode-h5web)__, which is sufficient for quick inspection and simple plot types. A more powerful option is __[Matplotlib](https://matplotlib.org/)__, and a plot of the fourty third sample path can be obtained as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "f = h5py.File(\"ou_process.h5\")\n",
    "dset = f[\"dataset\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = dset[42,:]\n",
    "print(f\"min: {arr.min():.2f}, max: {arr.max():.2f}, mean: {arr.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('_mpl-gallery')\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(np.arange(0,len(arr)), arr, linewidth=2.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "In this part of the tutorial, we demonstrated how to store a set of sample paths plus metadata in plain text, as an unformatted binary stream, and in an HDF5 file. Advantages and challenges are relative to circumstances, and pointless to belabor in the abstract. If circumstances change, it might be time for a change of approach. Here are a few considerations:\n",
    "\n",
    "The simplicity of plain text is hard to beat for small data sets. No special tools or libraries are needed to handle text. (There are, however, __[challenges](https://youtu.be/_mZBa3sqTrI?si=sKQKvFgserRq2uHf)__ with \"plain text\" the moment you go beyond US-ASCII.) Performance in space (file size) and time (marshalling overhead) deteriorates with data size. Common mitigations include compression and parallel processing, but the original simplicity is gone.\n",
    "\n",
    "Unformatted binary streams are fine as long as platforms and layouts are stable. The moment multiple platforms with different byte orders enter the mix, things get tricky. Change in the metadata or data is the biggest enemy. Not only is (separate) documentation in need of updates, but costly code changes to support legacy and new data might be necessary.\n",
    "\n",
    "The HDF5 framework takes care of all of the issues mentioned so far at the expense of a dependency on the HDF5 library and file format or HSDS. Common considerations before deciding on making your product dependent on the HDF5 framework include:\n",
    "\n",
    "1. **Licensing and Costs:** FOSS, BSD or Apache license, cost of ownership\n",
    "2. **Compatibility and Integration:** Great third-party support\n",
    "3. **Security and Privacy:** CVE-free\n",
    "4. **Support and Documentation:** Get support from The HDF Group; extensive documentation\n",
    "5. **Reliability and Performance:** Use in mission-critical applications; de facto standard for science and engineering data; Google Scholar\n",
    "6. **Updates and Longevity:** 25 year track record; regular maintenance releases, forward/backward compatibility guarantee\n",
    "7. **Vendor Lock-in:** FOSS & open specs.\n",
    "8. **Community and Ecosystem:** Outstanding, HUG events, Forum, Google Scholar, third-party support\n",
    "9. **Legal and Compliance Issues:** Permissive licensing; you know your legal envelope\n",
    "10. **Impact on Your Product Roadmap:** Where is the industry headed? Need room to grow? Move to the cloud? AI ready?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hdf5-tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
